{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary steps and makefile-style workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary steps are special steps that are executed to provide [targets](Understanding_Targets.html) that are required by others.\n",
    "\n",
    "For example, when the following step is executed with an input file `bamfile` (with extension `.bam`), it checks the existence of input file (`bamfile`), and a dependent index file (with extension `.bam.bai`).\n",
    "\n",
    "```sos\n",
    "[100 (call variant)]\n",
    "input:   bamfile\n",
    "depends: bamfile + '.bai'\n",
    "run:\n",
    "    # commands to call variants from \n",
    "    # input bam file\n",
    "```\n",
    "\n",
    "If the index file exists, generated either by another step or outside of SoS, sos will go ahead and execute the step. Otherwise  SoS will look in the script for a step that provides such a target, which would be similar to \n",
    "\n",
    "```sos\n",
    "[index_bam : provides='{sample}.bam.bai']\n",
    "input: '${sample}.bam'\n",
    "run:\n",
    "     samtools index ${input}\n",
    "```\n",
    "\n",
    "Such a step is defined by the **`provides`** option (or a **`shared`** option that will be discussed later) and is called an auxiliary step. In this particular case, if `bamfile=\"AS123.bam\"`, the requested file would be `AS123.bam.bai`. Through the matching mechanism of option `provides`, the `index_bam` step would be executed with variable `sample=\"AS123\"` and `output=[\"AS123.bam.bai\"]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An auxiliary step can trigger other auxiliary steps that form a DAG (Directed Acyclic Graph). Acutually, you can write workflows in a make-file style with all auxiliary steps and execute workflows defined by targets. If you are familiar with Makefile, especially [snakemake](https://bitbucket.org/johanneskoester/snakemake), it can be natural for you to implement your workflow in this style. The advantage of SoS is that **you can use either or both forward-style and makefile-style steps to define your workflow** and take advantages of both approaches. For example, people frequently need to create fake targets to trigger steps that do not produce any target in a makefile-style workflow system, but this is not needed in SoS because steps defined in forward-style will always be executed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step option `provides`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "An auxiliary step can be defined in the format of\n",
    "\n",
    "```python\n",
    "[step_name : provides=pattern]\n",
    "```\n",
    "\n",
    "where `pattern` can be\n",
    "\n",
    "* A file pattern such as `\"{sample}.bam.idx\"`\n",
    "* Other types of targets such as `executable(\"ms\")`\n",
    "* A list (sequence) of one or more file patterns and targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A file pattern is a filename with optional patterns with variable names enbraced in `{ }`. SoS matches filenames with the patterns and, if successful, assign variables with matched parts of the names. \n",
    "\n",
    "The following example first removes all local `*.bam` and `*.bam.bi` file, and executes three workflows defined by `targets`. We could execute them from command line\n",
    "```\n",
    "    sos run myscript --target TS1.bam\n",
    "```\n",
    "if the script is defined in `myscript.sos`, or from Jupyter notebook using\n",
    "```\n",
    "    %run --target TS1.bam\n",
    "```\n",
    "but using action `sos_run` allows us to execute multiple workflows as nested workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating target TS1.bam\n",
      "> compress input to TS1.bam\n",
      "\n",
      "Generating target TS1.bam.bai\n",
      "> index TS1.bam to TS1.bam.bai\n",
      "\n",
      "Generating target TS2.bam.bai\n",
      "> compress input to TS2.bam\n",
      "> index TS2.bam to TS2.bam.bai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre><font color=\"green\">## -- Preview output --</font></pre>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre> input: <a target=\"_blank\" href=\"TS2.bam\">TS2.bam</a>\n",
       "output: <a target=\"_blank\" href=\"TS2.bam.bai\">TS2.bam.bai</a>\n",
       "</pre>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre><font color=\"green\">> TS2.bam.bai (0 B):</font></pre>"
      ],
      "text/plain": [
       "\n",
       "> TS2.bam.bai (0 B):"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!rm -f *.bam *.bam.bai\n",
    "\n",
    "[compress: provides = '{filename}.bam']\n",
    "print(\"> ${step_name} input to ${output}\")\n",
    "sh:\n",
    "    touch ${output}\n",
    "\n",
    "[index: provides = '{filename}.bam.bai']\n",
    "input: \"${filename}.bam\"\n",
    "print(\"> ${step_name} ${input} to ${output}\")\n",
    "sh:\n",
    "    touch ${output}\n",
    "\n",
    "[default]\n",
    "print('Generating target TS1.bam')\n",
    "sos_run(targets='TS1.bam')\n",
    "print('\\nGenerating target TS1.bam.bai')\n",
    "sos_run(targets='TS1.bam.bai')\n",
    "print('\\nGenerating target TS2.bam.bai')\n",
    "sos_run(targets='TS2.bam.bai')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As you can see from the output, when the first workflow is executed with target `TS1.bam`, step `compress` is executed to produce it. Then the second workflow is executed with target `TS1.bam.bai`, step `index` is executed with `TS1.bam` generated from the first run. In the last run, both steps `compress` and `index` are executed to generate `TS2.bam`, and then `TS1.bam.bai`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean up\n",
    "!rm -f *.bam *.bam.bai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing workflows with auxiliary steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can execute forward-style workflows by specifying workflow name (can be `default`) from command line. The workflow can trigger auxiliary steps for the generation of unavailable targets. The workflows are executed and you generally have the mind-setting of \"how to process certain input file\".\n",
    "\n",
    "You can execute a makefile-style workflow by specifying one or more targets using option `-t` (target). SoS would collect all auxiliary steps in the script and create DAGs to generate these targets. Forward-style workflows defined in the script, if defined, would be ignored.\n",
    "\n",
    "You can specify both a forward-style workflow and a `-t` option. In this case a DAG would be created with both the forward-style workflow, and steps to produce the specified targets. The DAG would then be trimmed to a sub-DAG that produce the specified targets before it is executed. Note that in this case the target can be any output produced by the forward-style workflow, and does not have to be generated by an auxiliary step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm -rf *.txt *.ttt *.txt.gz \n",
    "%run default -t step.ttt.gz -f\n",
    "\n",
    "[compress: provides='{name}.gz']\n",
    "input: \"${name}\"\n",
    "print(\"Running step ${step_name} to generate ${output} from ${input}\")\n",
    "run:\n",
    "    touch ${output}\n",
    "\n",
    "[txt: provides='{name}.txt']\n",
    "print(\"Running step ${step_name} to generate ${output} from ${input}\")\n",
    "run:\n",
    "    touch ${output}\n",
    "\n",
    "[ttt: provides='{name}.ttt']\n",
    "print(\"Running step ${step_name} to generate ${output} from ${input}\")\n",
    "run:\n",
    "    touch ${output}\n",
    "\n",
    "[10]\n",
    "print(\"Running step ${step_name} to generate ${output} from ${input}\")\n",
    "\n",
    "[20]\n",
    "depends: \"step20.txt\"\n",
    "print(\"Running step ${step_name} to generate ${output} from ${input}\")\n",
    "\n",
    "[30]\n",
    "output: \"step30.txt\"\n",
    "print(\"Running step ${step_name} to generate ${output} from ${input}\")\n",
    "run:\n",
    "    touch ${output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos.kernel.SoS_Exporter",
   "pygments_lexer": "sos"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
